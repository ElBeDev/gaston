# ğŸ—£ï¸ Eva + OpenAI Live Voice Integration Workflow

## ğŸ¯ Objetivo

Integrar conversaciÃ³n en tiempo real por voz usando la OpenAI Realtime API (gpt-4o-realtime-preview) en Eva, con **chat unificado** que combina texto y voz en una sola interfaz.

---

## 1ï¸âƒ£ **Requerimientos Previos**

- Cuenta OpenAI con acceso a gpt-4o-realtime-preview (beta)
- API Key de OpenAI vÃ¡lida y habilitada para Realtime
- Infraestructura Eva corriendo (React frontend + Node.js backend)
- Certificado SSL (WebRTC requiere HTTPS para producciÃ³n)
- Permisos de micrÃ³fono en el navegador

---

## 2ï¸âƒ£ **Arquitectura General (Actualizada)**

```
[Usuario] ğŸ¤ ğŸ’¬
   â‡… (WebSocket + HTTP)
[UnifiedChat React] â€”â€”â€” [Backend Node.js/Express] â€”â€”â€” [OpenAI Realtime API]
```

- **Frontend**: **UnifiedChat** - Una sola interfaz para texto y voz, captura audio, maneja conversaciones
- **Backend**: Proxy WebSocket para voz + API REST para texto
- **OpenAI API**: Procesa audio/texto en tiempo real y responde

---

## 3ï¸âƒ£ **Estructura de archivos actual**

```
/frontend/src/components/UnifiedChat.js        # ğŸ†• COMPONENTE PRINCIPAL - Chat unificado texto + voz
/frontend/src/components/EvaAvatar.js          # Avatar animado de Eva 
/frontend/src/pages/ChatPage.js                # PÃ¡gina simplificada - solo renderiza UnifiedChat
/backend/src/routes/liveVoice.js               # WebSocket proxy para streaming continuo
/backend/src/routes/chat.js                    # Endpoints para mensajes de texto
/backend/src/routes/context.js                 # Sistema de contexto para persistir conversaciones
/backend/src/models/UserContext.js             # Modelo de datos para contexto de usuario
```

### ğŸ“ **Archivos deprecados/eliminados:**
- ~~`/frontend/src/components/EvaLiveVoice.js`~~ â†’ **Integrado en UnifiedChat**
- ~~`/frontend/src/components/ChatMain.js`~~ â†’ **Integrado en UnifiedChat**
- ~~Arquitectura separada de texto vs voz~~ â†’ **Todo unificado**

---

## 4ï¸âƒ£ **ImplementaciÃ³n Actual**

### A. **Frontend - UnifiedChat (Todo en uno)**
#### Archivo: `/frontend/src/components/UnifiedChat.js`

**ğŸ¯ CaracterÃ­sticas implementadas:**
- âœ… **Chat unificado** - Texto y voz en la misma ventana
- âœ… **ConversaciÃ³n continua por voz** - Como OpenAI Voice Mode
- âœ… **VAD automÃ¡tico** - DetecciÃ³n automÃ¡tica de voz
- âœ… **Interrupciones** - Parar a Eva mientras habla
- âœ… **BotÃ³n de voz integrado** - Al lado del input de texto
- âœ… **Mensajes con iconos** - ğŸ’¬ texto, ğŸ¤ voz usuario, ğŸ”Š voz Eva
- âœ… **Orden cronolÃ³gico correcto** - Conversaciones aparecen en orden
- âœ… **Estados visuales** - Listening, Speaking, Processing
- âœ… **BotÃ³n copiar** - En todas las respuestas de Eva
- âœ… **Historial persistente** - Carga automÃ¡tica del historial
- âœ… **Bordes de colores** - Mensajes de voz tienen borde distintivo

```javascript
// Estructura principal del UnifiedChat
const UnifiedChat = () => {
  // Estados unificados
  const [messages, setMessages] = useState([...]);
  const [conversationActive, setConversationActive] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  
  // Refs para WebSocket y audio
  const wsRef = useRef(null);
  const audioContextRef = useRef(null);
  const currentUserSpeechRef = useRef("");
  const currentEvaSpeechRef = useRef("");
  
  // Estado para manejar conversaciones pendientes (orden correcto)
  const [pendingConversation, setPendingConversation] = useState({
    userText: "", evaText: "", userReceived: false, evaReceived: false
  });

  // FunciÃ³n unificada para aÃ±adir mensajes
  const addMessage = (from, text, type = "text") => {
    const message = { from, text, type, timestamp: new Date().toISOString() };
    setMessages(prev => [...prev, message]);
  };

  // Manejo de texto - envÃ­o a API REST
  const handleSendText = async (e) => {
    // ... envÃ­o HTTP a /api/chat/message
  };

  // Manejo de voz - WebSocket streaming
  const startVoiceConversation = async () => {
    const ws = new WebSocket(`ws://localhost:3002/stream`);
    // ... configuraciÃ³n WebSocket con VAD automÃ¡tico
  };

  // Procesamiento de eventos de voz con orden correcto
  const handleVoiceEvent = (event) => {
    switch (event.type) {
      case 'conversation.item.input_audio_transcription.completed':
        // Guardar transcripciÃ³n de usuario y aÃ±adir mensaje inmediatamente
        setPendingConversation(prev => ({...prev, userText: event.transcript, userReceived: true}));
        break;
        
      case 'response.audio_transcript.done':
        // Guardar transcripciÃ³n de Eva
        setPendingConversation(prev => ({...prev, evaText: event.transcript, evaReceived: true}));
        break;
        
      case 'response.done':
        // Finalizar respuesta - mensajes se aÃ±aden por useEffect cuando estÃ¡n completos
        break;
    }
  };

  // useEffect para aÃ±adir conversaciones completas en orden correcto
  useEffect(() => {
    if (pendingConversation.userReceived && pendingConversation.evaReceived && 
        pendingConversation.userText && pendingConversation.evaText) {
      
      // AÃ±adir usuario primero
      addMessage("user", pendingConversation.userText, "voice");
      
      // AÃ±adir Eva despuÃ©s con delay mÃ­nimo para asegurar orden
      setTimeout(() => {
        addMessage("eva", pendingConversation.evaText, "voice");
      }, 50);
      
      // Limpiar conversaciÃ³n pendiente
      setPendingConversation({userText: "", evaText: "", userReceived: false, evaReceived: false});
    }
  }, [pendingConversation]);

  return (
    // JSX unificado con input de texto + botÃ³n de voz integrado
    <div style={{...}}>
      {/* Header con avatar */}
      <div>
        <EvaAvatar speaking={isSpeaking || isListening} />
        <h2>ğŸ’¬ Chat con Eva</h2>
        <p>Escribe o habla - Todo en un solo lugar</p>
      </div>
      
      {/* Ãrea de mensajes unificada */}
      <div>
        {messages.map((msg, i) => (
          <div key={i} style={{
            border: msg.type === "voice" ? "2px solid" : "none",
            borderColor: msg.from === "user" ? "#4caf50" : "#ff1744"
          }}>
            {/* Icono segÃºn tipo de mensaje */}
            {msg.type === "voice" ? (msg.from === "user" ? "ğŸ¤" : "ğŸ”Š") : (msg.from === "user" ? "ğŸ’¬" : "ğŸ¤–")}
            <span>{msg.type === "voice" ? "Voz" : "Texto"}</span>
            <div>{msg.text}</div>
            {/* BotÃ³n copiar para respuestas de Eva */}
            {msg.from === "eva" && <button onClick={() => copyToClipboard(msg.text)}>ğŸ“‹</button>}
          </div>
        ))}
      </div>
      
      {/* Input unificado - texto + voz */}
      <div>
        <form onSubmit={handleSendText}>
          <input placeholder="Escribe tu mensaje..." />
          <button type="submit">ğŸ’¬ Enviar</button>
        </form>
        
        {/* BotÃ³n de voz integrado */}
        <button onClick={handleVoiceToggle} style={{
          background: conversationActive ? "linear-gradient(135deg, #ff1744, #ff4569)" : "linear-gradient(135deg, #4caf50, #66bb6a)"
        }}>
          {conversationActive ? "â¹ï¸" : "ğŸ¤"}
        </button>
      </div>
    </div>
  );
};
```

#### Archivo: `/frontend/src/pages/ChatPage.js` (Simplificado)

```javascript
import React from 'react';
import { Box } from '@mui/material';
import UnifiedChat from "../components/UnifiedChat";

const ChatPage = () => {
  return (
    <Box sx={{ /* styling */ }}>
      <UnifiedChat />
    </Box>
  );
};
```

---

### B. **Backend (Sin cambios mayores)**
#### Archivo: `/backend/src/routes/liveVoice.js`

**WebSocket proxy para streaming continuo:**

```javascript
// WebSocket server en puerto 3002 para streaming
const initializeWebSocketServer = () => {
  wss = new WebSocket.Server({ port: 3002, path: '/stream' });
  
  wss.on('connection', (clientWs) => {
    let openaiWs = null;
    
    clientWs.on('message', async (message) => {
      const event = JSON.parse(message);
      
      if (event.type === 'session.update') {
        // Conectar a OpenAI con VAD habilitado
        openaiWs = new WebSocket("wss://api.openai.com/v1/realtime", {
          headers: {
            "Authorization": "Bearer " + process.env.OPENAI_API_KEY,
            "OpenAI-Beta": "realtime=v1"
          }
        });
        
        openaiWs.on('message', (data) => {
          // CRITICAL: Forward inmediatamente sin procesamiento
          if (clientWs.readyState === WebSocket.OPEN) {
            clientWs.send(data);
          }
        });
      } else if (openaiWs?.readyState === WebSocket.OPEN) {
        // Proxy de eventos de audio
        openaiWs.send(JSON.stringify(event));
      }
    });
  });
};
```

#### Archivo: `/backend/src/routes/chat.js` (Sin cambios)

- Endpoints para chat de texto tradicional
- `POST /api/chat/message` - Enviar mensaje de texto
- `GET /api/chat/history/:userId` - Obtener historial

---

## 5ï¸âƒ£ **Flujo de usuario actual**

### **ğŸ’¬ Modo Texto:**
1. Usuario escribe mensaje â†’ Enter o botÃ³n "ğŸ’¬ Enviar"
2. Mensaje aparece en chat con icono ğŸ’¬
3. Eva responde vÃ­a API REST â†’ Aparece con icono ğŸ¤–
4. BotÃ³n ğŸ“‹ para copiar respuesta

### **ğŸ¤ Modo Voz:**
1. Usuario presiona botÃ³n ğŸ¤ â†’ Inicia conversaciÃ³n continua
2. Usuario habla naturalmente â†’ VAD detecta automÃ¡ticamente
3. TranscripciÃ³n aparece en chat con icono ğŸ¤ y borde verde
4. Eva responde automÃ¡ticamente â†’ Aparece con icono ğŸ”Š y borde rojo
5. Usuario puede interrumpir a Eva hablando
6. Ciclo continÃºa hasta presionar â¹ï¸

### **ğŸ”„ Modo HÃ­brido:**
- Cambiar entre texto y voz dinÃ¡micamente
- Todo aparece en la misma ventana cronolÃ³gicamente
- Historial persistente de ambos tipos

---

## 6ï¸âƒ£ **Problemas resueltos en la nueva arquitectura**

### âœ… **Problema: Mensajes de voz aparecÃ­an desordenados**
**SoluciÃ³n:** 
- Sistema de `pendingConversation` que espera ambas transcripciones
- `useEffect` que aÃ±ade mensajes en orden correcto con delay de 50ms
- Usuario siempre aparece antes que Eva

### âœ… **Problema: Interfaz fragmentada (texto vs voz)**
**SoluciÃ³n:**
- `UnifiedChat` - Una sola interfaz para todo
- BotÃ³n de voz integrado al lado del input de texto
- Mensajes mezclados cronolÃ³gicamente con iconos distintivos

### âœ… **Problema: Transcripciones vacÃ­as en `response.done`**
**SoluciÃ³n:**
- Usar `currentUserSpeechRef` y `currentEvaSpeechRef` para evitar state stale
- AÃ±adir mensajes cuando llegan las transcripciones, no en `response.done`
- Manejo de eventos `conversation.item.input_audio_transcription.completed`

### âœ… **Problema: Frontend recibÃ­a datos binarios mezclados**
**SoluciÃ³n:**
```javascript
ws.onmessage = (event) => {
  if (event.data instanceof Blob) {
    event.data.text().then(text => {
      const serverEvent = JSON.parse(text);
      handleVoiceEvent(serverEvent);
    });
  }
  // ... manejar otros tipos de datos
};
```

### âœ… **Problema: Estados de conversaciÃ³n confusos**
**SoluciÃ³n:**
- Estados visuales claros: "Te escucho...", "Eva hablando...", "Tu turno..."
- Indicador de estado con color y emoji
- Avatar animado que responde al estado actual

---

## 7ï¸âƒ£ **CaracterÃ­sticas finales implementadas**

### **ğŸ¯ UnifiedChat:**
âœ… **Chat unificado completo** - Texto y voz en una interfaz  
âœ… **Orden cronolÃ³gico perfecto** - Conversaciones en secuencia correcta  
âœ… **Iconos distintivos** - ğŸ’¬ğŸ¤– texto, ğŸ¤ğŸ”Š voz  
âœ… **Bordes de colores** - Verde usuario, rojo Eva para voz  
âœ… **BotÃ³n copiar universal** - En todas las respuestas de Eva  
âœ… **Historial persistente** - Carga automÃ¡tica de conversaciones previas  
âœ… **Estados visuales avanzados** - Feedback en tiempo real  
âœ… **Responsive design** - Se adapta a diferentes tamaÃ±os  

### **ğŸ¤ ConversaciÃ³n de voz:**
âœ… **VAD automÃ¡tico** - DetecciÃ³n server-side sin botones manuales  
âœ… **Interrupciones en tiempo real** - Parar a Eva mientras habla  
âœ… **Streaming bidireccional** - Latencia mÃ­nima  
âœ… **TranscripciÃ³n automÃ¡tica** - Usuario y Eva transcritos  
âœ… **Un solo botÃ³n** - Start/Stop conversaciÃ³n completa  
âœ… **Manejo robusto de WebSocket** - ReconexiÃ³n y error handling  

### **ğŸ’¬ Chat de texto:**
âœ… **API REST tradicional** - EnvÃ­o HTTP estÃ¡ndar  
âœ… **Historial completo** - Persistencia en base de datos  
âœ… **Typing indicators** - Feedback mientras Eva responde  
âœ… **Error handling** - Manejo graceful de errores de API  

---

## 8ï¸âƒ£ **ConfiguraciÃ³n tÃ©cnica actual**

### **Endpoints:**
- `WS ws://localhost:3002/stream` - Streaming de voz continuo
- `POST /api/chat/message` - EnvÃ­o de mensajes de texto
- `GET /api/chat/history/:userId` - Historial de conversaciones
- `GET/PUT /api/context/:userId` - Manejo de contexto

### **Puertos:**
- **3000** - Frontend React
- **3001** - API HTTP Express
- **3002** - WebSocket server para voz

### **Variables de entorno:**
```bash
OPENAI_API_KEY=sk-...  # Con acceso a Realtime API
```

---

## 9ï¸âƒ£ **Roadmap actualizado**

### **âœ… Completado:**
- [x] Prototipo bÃ¡sico de Live Voice
- [x] IntegraciÃ³n con backend y OpenAI
- [x] TranscripciÃ³n bidireccional
- [x] Sistema de memoria conversacional
- [x] **UnifiedChat - Interfaz Ãºnica para texto + voz**
- [x] **Orden cronolÃ³gico correcto en conversaciones**
- [x] **VAD automÃ¡tico y detecciÃ³n de interrupciones**
- [x] **Estados visuales avanzados**
- [x] **Manejo robusto de WebSocket y eventos**

### **ğŸ”„ En progreso:**
- [ ] MigraciÃ³n a AudioWorklet (reemplazar ScriptProcessorNode)
- [ ] OptimizaciÃ³n de latencia adicional
- [ ] Testing en dispositivos mÃ³viles


### **ğŸ“‹ PrÃ³ximos pasos:**
1. **CaracterÃ­sticas avanzadas:**
   - Indicador de volumen del micrÃ³fono
   - ConfiguraciÃ³n de voz de Eva (alloy, echo, fable)
   - Shortcuts de teclado (Space para push-to-talk)
   - Soporte multiidioma

2. **IntegraciÃ³n de Email (nuevo workflow):**
   - [Ver workflow detallado aquÃ­: Eva + Google Email Integration](#%20%F0%9F%93%A7%20Eva%20+%20Google%20Email%20Integration%20Workflow.md)
   - Login con Google y acceso a Gmail desde Eva
   - RedacciÃ³n, envÃ­o y lectura de correos desde la interfaz unificada

3. **OptimizaciÃ³n tÃ©cnica:**
   - Reducir latencia de WebSocket
   - CompresiÃ³n de audio mÃ¡s eficiente
   - ReconexiÃ³n automÃ¡tica inteligente

4. **ProducciÃ³n:**
   - Deploy con HTTPS (requerido para micrÃ³fono)
   - Load balancing para WebSocket connections
   - Monitoreo de performance y analytics

---

## ğŸ¯ **ComparaciÃ³n: Antes vs Ahora**

| Aspecto | **Antes (Separado)** | **Ahora (UnifiedChat)** |
|---|---|---|
| **Interfaz** | Chat texto + EvaLiveVoice separados | Una sola interfaz unificada |
| **Archivos** | ChatMain.js + EvaLiveVoice.js | UnifiedChat.js (todo en uno) |
| **Flujo de mensajes** | Sistemas separados con props complejos | Estado unificado con addMessage() |
| **Orden de mensajes** | Problemas de sincronizaciÃ³n | Orden cronolÃ³gico perfecto |
| **Experiencia de usuario** | Confuso cambiar entre modos | Fluido cambio texto â†” voz |
| **Mantenimiento** | CÃ³digo duplicado, props complejos | Una sola fuente de verdad |
| **Estados** | Dispersos entre componentes | Centralizados y coherentes |

**ğŸš€ Resultado: Interfaz mucho mÃ¡s limpia, mantenible y funcional!**
